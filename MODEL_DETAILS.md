# –î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π

## –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
1. [–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Ä–æ–≤–Ω—è —Å—Ç—Ä–µ—Å—Å–∞](#1-–ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ-—É—Ä–æ–≤–Ω—è-—Å—Ç—Ä–µ—Å—Å–∞)
2. [–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π](#2-–≥–µ–Ω–µ—Ä–∞—Ü–∏—è-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π)
3. [–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ä–µ—à–µ–Ω–∏—è](#3-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ-—Ä–µ—à–µ–Ω–∏—è)

[üìö –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞](README.md)

---

**–ü–æ—á–µ–º—É Tensorflow?**
>TensorFlow –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –≥–æ—Ç–æ–≤—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è —Å–∫–≤–æ–∑–Ω–æ–≥–æ ML-–ø–∞–π–ø–ª–∞–π–Ω–∞ ‚Äî –æ—Ç —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ —Å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π –¥–æ –ø—Ä–æ–¥–∞–∫—à–Ω-–¥–µ–ø–ª–æ—è, —á—Ç–æ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–æ–≤ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.
> –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏ –±—ã—Å—Ç—Ä–∞—è —Ä–∞–±–æ—Ç–∞ –Ω–∞ CPU. 

## 1. –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Ä–æ–≤–Ω—è —Å—Ç—Ä–µ—Å—Å–∞

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏
```python
model = tf.keras.Sequential([
    tf.keras.layers.Dense(64, activation='relu', input_shape=(13,)),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l1_l2(0.01)),
    tf.keras.layers.Dense(1)
])
```
### –°–ª–æ–π –∑–∞ —Å–ª–æ–µ–º:
**–í—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π:** 64 –Ω–µ–π—Ä–æ–Ω–∞ —Å ReLU + L2-—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è (Œª=0.01)

**Batch Normalization:** –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–π –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Å–ª–æ—è

**Dropout (30%):** –ò—Å–∫–ª—é—á–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤ –¥–ª—è –±–æ—Ä—å–±—ã —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º

**–°–∫—Ä—ã—Ç—ã–µ —Å–ª–æ–∏:** 32 –Ω–µ–π—Ä–æ–Ω–∞ —Å ReLU + –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è L1/L2-—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è (Œª=0.01)

**–í—ã—Ö–æ–¥:** 1 –Ω–µ–π—Ä–æ–Ω —Å –ª–∏–Ω–µ–π–Ω–æ–π –∞–∫—Ç–∏–≤–∞—Ü–∏–µ–π –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
```python
checkpoint = tf.keras.callbacks.ModelCheckpoint(
    'models/stress_model.keras',
    save_best_only=True,
    monitor='val_loss',
    mode='min'
)

lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=10
)

history = model.fit(
    X_train, y_train,
    epochs=200,
    batch_size=64,
    validation_split=0.2,
    callbacks=[checkpoint, lr_scheduler],
    verbose=1
)
```

### –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏
**–¢–∏–ø –∑–∞–¥–∞—á–∏:** –†–µ–≥—Ä–µ—Å—Å–∏—è

**–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è:**

- L2-—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –≤ –ø–µ—Ä–≤–æ–º —Å–ª–æ–µ

- –°–º–µ—à–∞–Ω–Ω–∞—è L1/L2-—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –≤–æ –≤—Ç–æ—Ä–æ–º —Å–∫—Ä—ã—Ç–æ–º —Å–ª–æ–µ

**–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è:**

- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–º–µ–Ω—å—à–µ–Ω–∏–µ learning rate –ø—Ä–∏ –ø–ª–∞—Ç–æ (–ø–∞—Ü–∏–µ–Ω—Ç=10 —ç–ø–æ—Ö)

- –ü–∞–∫–µ—Ç–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–∂–¥—É —Å–ª–æ—è–º–∏

- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –ø–æ val_loss

**–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞:**

- MAE (Mean Absolute Error)
- MSE (Mean Squared Error)

**–°—Ç—Ä–∞—Ç–µ–≥–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏:**

- 20% –¥–∞–Ω–Ω—ã—Ö –≤—ã–¥–µ–ª–µ–Ω–æ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏

- –¢–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä: 20% –æ—Ç –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

---

## 2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏
```python
model = tf.keras.Sequential([
    tf.keras.layers.Dense(32, activation='relu', input_shape=(1,)),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(16, activation='relu'),
    tf.keras.layers.Dense(y.shape[1], activation='sigmoid')
])
```

### –°–ª–æ–π –∑–∞ —Å–ª–æ–µ–º:
**–í—Ö–æ–¥:** –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å —Å—Ç—Ä–µ—Å—Å–∞ (0-1)

**–°–∫—Ä—ã—Ç—ã–µ —Å–ª–æ–∏:** 32 –Ω–µ–π—Ä–æ–Ω–∞ —Å ReLU

**Dropout (30%):** –°–ª—É—á–∞–π–Ω–æ–µ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–æ–≤ –¥–ª—è –±–æ—Ä—å–±—ã —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º

**–í—Ç–æ—Ä–æ–π —Å–∫—Ä—ã—Ç—ã–π —Å–ª–æ–π:** 16 –Ω–µ–π—Ä–æ–Ω–æ–≤ —Å ReLU

**–í—ã—Ö–æ–¥:** y.shape[1] –Ω–µ–π—Ä–æ–Ω–æ–≤ (—Å–∏–≥–º–æ–∏–¥–∞ –¥–ª—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–π –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏)

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è

```python
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),
    loss='binary_crossentropy',
    metrics=[
        tf.keras.metrics.Precision(name='precision'),
        tf.keras.metrics.Recall(name='recall'),
        tf.keras.metrics.AUC(name='auc')
    ]
)

early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True
)
```

### –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏
**–¢–∏–ø –∑–∞–¥–∞—á–∏:** –ú–ú—É–ª—å—Ç–∏-–ª–µ–π–±–ª –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –º–µ—Ö–∞–Ω–∏–∑–º–æ–≤ –±–æ—Ä—å–±—ã —Å–æ —Å—Ç—Ä–µ—Å—Å–æ–º

**–ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã:**

- –î–æ–±–∞–≤–ª–µ–Ω–∏–µ Dropout (30%) –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
- –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π –ø–æ–¥ —Ä–∞–∑–º–µ—Ä —Ü–µ–ª–µ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö (y.shape[1])

**–ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏:**

- Precision: –î–æ–ª—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
- Recall: –ü–æ–∫—Ä—ã—Ç–∏–µ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
- AUC: –ö–∞—á–µ—Å—Ç–≤–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤

**–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è:**

- –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ —É–ª—É—á—à–µ–Ω–∏–π 5 —ç–ø–æ—Ö
- –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π learning rate (—Å—Ç–∞—Ä—Ç–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ 0.005)

**–°—Ç—Ä–∞—Ç–µ–≥–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏:**

- –¢–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä: 20% –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏: 20% –æ—Ç —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö:**

- –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ: –±–∏–Ω–∞—Ä–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
- –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤—Ö–æ–¥–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ (Mental Stress Level) –≤ –¥–∏–∞–ø–∞–∑–æ–Ω [0, 1]

**–ö–ª–∞—Å—Å—ã —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π (–ø—Ä–∏–º–µ—Ä):**

- –ú–µ–¥–∏—Ç–∞—Ü–∏—è
- –§–∏–∑–∏—á–µ—Å–∫–∏–µ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è
- –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞
- –ö–æ—Ä—Ä–µ–∫—Ü–∏—è —Å–Ω–∞
- –°–æ—Ü–∏–∞–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
- –¢–∞–π–º-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç
- –î–∏–µ—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
- –§–∏–Ω–∞–Ω—Å–æ–≤—ã–π –ø–ª–∞–Ω

---


## 3. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ä–µ—à–µ–Ω–∏—è

### –†–∞–±–æ—Ç–∞ —Å –º–∞–ª—ã–º –æ–±—ä–µ–º–æ–º –¥–∞–Ω–Ω—ã—Ö (20 000 samples)
**–°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è:**
-  **–ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö**: 
  - –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è L1/L2 –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –≤–µ—Å–æ–≤
  - Dropout —Å–ª–æ–∏ (30%) –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –∫–æ–∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –Ω–µ–π—Ä–æ–Ω–æ–≤
  - Batch Normalization –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è
-  **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è:**: 
  - Adaptive Learning Rate (ReduceLROnPlateau)
  - Early Stopping —Å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º –ª—É—á—à–∏—Ö –≤–µ—Å–æ–≤
-  **–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö:**:
  - –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –≤—ã–±–æ—Ä–∫–∏
  - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤

### –≠—Ç–∞–ø—ã –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞:
1. **–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤**

- –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö:
  - Gender: Male ‚Üí 1, Female ‚Üí 0
  - Counseling Attendance: Yes ‚Üí 1, No ‚Üí 0
- –ú—É–ª—å—Ç–∏-—Ö–æ—Ç –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –º–µ—Ö–∞–Ω–∏–∑–º–æ–≤ –ø—Ä–µ–æ–¥–æ–ª–µ–Ω–∏—è —Å—Ç—Ä–µ—Å—Å–∞
- –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:
  - total_weekly_hours: —Å—É–º–º–∞ —É—á–µ–±–Ω—ã—Ö –∏ —Ä–∞–±–æ—á–∏—Ö —á–∞—Å–æ–≤
  - sleep_efficiency: –æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å–Ω–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é —Å–æ—Ü—Å–µ—Ç–µ–π

2. **–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö**

- –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ (User ID)
- –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Z-score –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è)
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (5% –æ—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞)

3. **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:**

- –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ 2 –ø–æ—Ç–æ–∫–∞:
  - stress_data.csv: 13 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ + —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è (—Ä–µ–≥—Ä–µ—Å—Å–∏—è)
  - mechanism_data.csv: 1 –ø—Ä–∏–∑–Ω–∞–∫ + 10 –±–∏–Ω–∞—Ä–Ω—ã—Ö –º–µ—Ç–æ–∫ (–º–Ω–æ–≥–æ–∑–∞–¥–∞—á–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è)

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä –º–æ–¥–µ–ª–µ–π

| –ü–∞—Ä–∞–º–µ—Ç—Ä      | –ú–æ–¥–µ–ª—å —Å—Ç—Ä–µ—Å—Å–∞                           | –ú–æ–¥–µ–ª—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π                       |
|---------------|------------------------------------------|-------------------------------------------|
| –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞   | 64-32-1 Dense                            | 32-16-10 Dense                            |
| –ê–∫—Ç–∏–≤–∞—Ü–∏–∏     | ReLU (—Å–∫—Ä—ã—Ç—ã–µ —Å–ª–æ–∏),<br/> Linear (–≤—ã—Ö–æ–¥) | ReLU (—Å–∫—Ä—ã—Ç—ã–µ —Å–ª–æ–∏),<br/> Sigmoid (–≤—ã—Ö–æ–¥) |
| –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä   | Adam (lr=0.001)                          | Adam (lr=0.005)                           |
| –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è | L2 (0.01) + Dropout                      | Dropout (30%)                             |
| –ú–µ—Ç—Ä–∏–∫–∏       | MSE, MAE                                 | Precision, Recall, AUC                    |
| –û–±—É—á–µ–Ω–∏–µ      | 200 —ç–ø–æ—Ö (–ø–∞–∫–µ—Ç 64)                      | L50 —ç–ø–æ—Ö (–ø–∞–∫–µ—Ç 32)                       |
| –ö–æ–ª–±–µ–∫–∏       | ModelCheckpoint + ReduceLROnPlateau      | EarlyStopping                             |


**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏:**

- –î–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏:
  - –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è StandardScaler
  - –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ learning rate
  - –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ 20% —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
  
- –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:
  - –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (0-10 ‚Üí 0-1)
  - –ú–Ω–æ–≥–æ–∑–∞–¥–∞—á–Ω–∞—è –±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
  - –ü–æ—Ä–æ–≥–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (sigmoid > 0.5)

**–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:**

- –†–µ–≥—Ä–µ—Å—Å–∏—è:
    - –ì—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
    - –ê–Ω–∞–ª–∏–∑ –∫—Ä–∏–≤—ã—Ö –æ–±—É—á–µ–Ω–∏—è (train/val loss)

- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è:
  - –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –º–µ—Ç—Ä–∏–∫ precision-recall
  - –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è ROC-–∫—Ä–∏–≤—ã—Ö –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–µ—Ö–∞–Ω–∏–∑–º–∞

**–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:**

- –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –ü–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –ø–∞–º—è—Ç–∏
- –ü–∞–∫–µ—Ç–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–µ—Ñ–µ—Ç—á–∏–Ω–≥–æ–º
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤ TensorFlow
